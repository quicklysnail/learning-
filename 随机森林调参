import pandas as pd
import numpy as py
from sklearn.grid_search import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import matplotlib.pylab as plt
%matplotlib inline
from sklearn import cross_validation, metrics

all_data_train = pd.read_csv('Desktop/kaggle example/Titanic_data/all_data_train.csv')
all_data_test = pd.read_csv('Desktop/kaggle example/Titanic_data/all_data_test.csv')
print(all_data_train.shape)
print(all_data_test.shape)
all_data_train.head()

X = all_data_train.as_matrix()[: ,1:]
y = all_data_train.as_matrix()[: , 0]
print(X.shape)
print(y.shape)

rf0 = RandomForestClassifier(oob_score=True , random_state =10)
rf0.fit(X ,y)
print(rf0.oob_score_)
y_predprob = rf0.predict_proba(X)[:,1]
print('AUC Score(Train): %f'%metrics.roc_auc_score(y , y_predprob))

rf0

param_test1 = {'n_estimators':[i for i in range(10,71,10)]}
gsearch1 = GridSearchCV(estimator =RandomForestClassifier(min_samples_split=100 , 
                                                          min_samples_leaf = 20,
                                                          max_depth=8,
                                                          max_features='sqrt',
                                                          random_state=10
                                                         ),
                       param_grid=param_test1 , scoring='roc_auc' , cv=5)
gsearch1.fit(X ,y)
gsearch1.grid_scores_ , gsearch1.best_params_ ,gsearch1.best_score_

param_test2 = {'max_depth':[i for i in range(3,14,2)], 'min_samples_split':[a for a in range(20,201,20)]}
gsearch2 = GridSearchCV(estimator =RandomForestClassifier(n_estimators=10 , 
                                                          min_samples_leaf = 20,
                                                          max_features='sqrt',
                                                          oob_score=True,
                                                          random_state=10
                                                         ),
                       param_grid=param_test2 , scoring='roc_auc' , cv=5)
gsearch2.fit(X,y)
gsearch2.grid_scores_ , gsearch2.best_params_ ,gsearch2.best_score_

rf1 = RandomForestClassifier(n_estimators=10,max_depth=9,min_samples_split=20,min_samples_leaf=20,max_features='sqrt',oob_score=True , random_state =10)
rf1.fit(X,y)
print(rf1.oob_score_)

param_test3 = {'min_samples_split':[i for i in range(5,40,5)] , 'min_samples_leaf':[a for a in range(10,60,10)]}
gsearch3 = GridSearchCV(estimator =RandomForestClassifier(n_estimators=10 , 
                                                          max_depth=10,
                                                          max_features='sqrt',
                                                          oob_score=True,
                                                          random_state=10
                                                         ),
                       param_grid=param_test3 , scoring='roc_auc' , cv=5)
gsearch3.fit(X,y)
gsearch3.grid_scores_ , gsearch3.best_params_ ,gsearch3.best_score_

param_test4 = {'max_features':[i for i in range(3,15,2)]}
gsearch4 = GridSearchCV(estimator =RandomForestClassifier(n_estimators=10 , 
                                                          max_depth=10,
                                                          min_samples_leaf=10,
                                                          min_samples_split=5,
                                                          
                                                          oob_score=True,
                                                          random_state=10
                                                         ),
                       param_grid=param_test4 , scoring='roc_auc' , cv=5)
gsearch4.fit(X,y)
gsearch4.grid_scores_ , gsearch4.best_params_ ,gsearch4.best_score_

rf2 = RandomForestClassifier(n_estimators=10,max_depth=9,min_samples_split=5,min_samples_leaf=10,max_features=5,oob_score=True , random_state =10)
rf2.fit(X,y)
print(rf2.oob_score_)




