import pandas as pd
import numpy as np
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.grid_search import GridSearchCV
from sklearn import cross_validation , metrics

import matplotlib.pylab as plt
%matplotlib inline
from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 12, 4


all_data_train = pd.read_csv('Desktop/kaggle example/Titanic_data/all_data_train.csv')
all_data_test = pd.read_csv('Desktop/kaggle example/Titanic_data/all_data_test.csv')
print(all_data_train.shape)
print(all_data_test.shape)


def modelfit(alg, dtrain, dtest ,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):

    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(dtrain.as_matrix()[: ,1:], label=dtrain.as_matrix()[: ,0])
        xgtest = xgb.DMatrix(dtest.as_matrix()[: , :])
        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds ,early_stopping_rounds=early_stopping_rounds)
        alg.set_params(n_estimators=cvresult.shape[0])
    
    #建模
    alg.fit(dtrain.as_matrix()[: ,1:], dtrain.as_matrix()[: ,0],eval_metric='auc')
        
    #对训练集预测
    dtrain_predictions = alg.predict(dtrain.as_matrix()[: ,1:])
    dtrain_predprob = alg.predict_proba(dtrain.as_matrix()[: ,1:])[:,1]
        
    #输出模型的一些结果
    #print(dtrain_predictions)
    #print(alg.predict_proba(dtrain.as_matrix()[: ,1:]))
    print(cvresult.shape[0])
    print "\n关于现在这个模型"
    print "准确率 : %.4g" % metrics.accuracy_score(dtrain.as_matrix()[: ,0], dtrain_predictions)
    print "AUC 得分 (训练集): %f" % metrics.roc_auc_score(dtrain.as_matrix()[: ,0], dtrain_predprob)
                
    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)
    feat_imp.plot(kind='bar', title='Feature Importances')
    plt.ylabel('Feature Importance Score')

## 第1步- 对于高的学习率找到最合适的estimators个数
 xgb1 = XGBClassifier(
            learning_rate=0.1,
            n_estimators =1000,
            max_depth=5,
            min_child_weight =1,
            gamma = 0,
            subsample=0.8,
            colsample_bytree = 0.8,
            objective ='binary:logistic' ,
            nthread=4,
            scale_pos_weight=1,
            seed = 27
            )

modelfit(xgb1 , all_data_train ,all_data_test)

## 对subsample 和 max_features 用grid search查找最好的参数
param_test1 = {'max_depth':range(3,10,2) , 'min_child_weight':range(1 , 6 , 2)}
gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=185,
                                                  max_depth = 5,min_child_weight=1,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test1 ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch1.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch1.grid_scores_ , gsearch1.best_params_ ,gsearch1.best_score_

param_test2 = {'max_depth':[6,7,8] , 'min_child_weight':[4,5,6]}
gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=185,
                                                  max_depth = 5,min_child_weight=1,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test2 ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch2.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch2.grid_scores_ , gsearch2.best_params_ ,gsearch2.best_score_


param_test2b = { 'min_child_weight':[6,8,10,12]}
gsearch2b = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=185,
                                                  max_depth = 6,min_child_weight=2,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test2b ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch2b.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch2b.grid_scores_ , gsearch2b.best_params_ ,gsearch2b.best_score_

## 选择合适的gamma
param_test3 = { 'gamma':[i/10.0 for i in range(0,5)]}
gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=185,
                                                  max_depth = 6,min_child_weight=6,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test3 ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch3.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch3.grid_scores_ , gsearch3.best_params_ ,gsearch3.best_score_

xgb2 = XGBClassifier(
            learning_rate=0.1,
            n_estimators =1000,
            max_depth=6,
            min_child_weight =6,
            gamma = 0,
            subsample=0.8,
            colsample_bytree = 0.8,
            objective ='binary:logistic' ,
            nthread=4,
            scale_pos_weight=1,
            seed = 27
            )

modelfit(xgb2 , all_data_train ,all_data_test)


## 对subsample 和 colsample_bytree用grid search寻找最合适的参数
param_test4 = { 'subsample':[i/10.0 for i in range(6,10)],
              'colsample_bytree':[i/10.0 for i in range(6 , 10)]}
gsearch4 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=120,
                                                  max_depth = 6,min_child_weight=6,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test4 ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch4.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch4.grid_scores_ , gsearch4.best_params_ ,gsearch4.best_score_

param_test4b = { 'subsample':[i/100.0 for i in range(85,100,5)],
              'colsample_bytree':[i/100.0 for i in range(75,90,5)]}
gsearch4b = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=120,
                                                  max_depth = 6,min_child_weight=6,gamma=0,
                                                  subsample=0.8 , colsample_bytree=0.9,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test4b ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch4b.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch4b.grid_scores_ , gsearch4b.best_params_ ,gsearch4b.best_score_


param_test5 = { 'reg_alpha':[1e-5 , 1e-2,0.1,100],
              }
gsearch5 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=120,
                                                  max_depth = 6,min_child_weight=6,gamma=0,
                                                  subsample=0.9 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test5 ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch5.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch5.grid_scores_ , gsearch5.best_params_ ,gsearch5.best_score_


param_test5b = { 'reg_alpha':[0,0.001,0.005,0.01,0.05],
              }
gsearch5b = GridSearchCV(estimator = XGBClassifier(learning_rate=0.1 , n_estimators=120,
                                                  max_depth = 6,min_child_weight=6,gamma=0,
                                                  subsample=0.9 , colsample_bytree=0.8,
                                                  objective = 'binary:logistic',nthread=4,
                                                  scale_pos_weight=1,seed=27)
                       ,param_grid=param_test5b ,scoring='roc_auc' , n_jobs=4 , iid=False ,cv=5
                       )
gsearch5b.fit(all_data_train.as_matrix()[: ,1:] , all_data_train.as_matrix()[: ,0])
gsearch5b.grid_scores_ , gsearch5b.best_params_ ,gsearch5b.best_score_


xgb3 = XGBClassifier(
            learning_rate=0.1,
            n_estimators =1000,
            max_depth=6,
            min_child_weight =6,
            gamma = 0,
            subsample=0.9,
            colsample_bytree = 0.8,
            reg_alpha = 0.01,
            objective ='binary:logistic' ,
            nthread=4,
            scale_pos_weight=1,
            seed = 27
            )

modelfit(xgb3 , all_data_train ,all_data_test)


xgb4 = XGBClassifier(
            learning_rate=0.1,
            n_estimators =5000,
            max_depth=6,
            min_child_weight =6,
            gamma = 0,
            subsample=0.9,
            colsample_bytree = 0.8,
            reg_alpha = 0.01,
            objective ='binary:logistic' ,
            nthread=4,
            scale_pos_weight=1,
            seed = 27
            )

modelfit(xgb4 , all_data_train ,all_data_test)




